{"cells":[{"cell_type":"markdown","id":"e0fa1463","metadata":{"papermill":{"duration":0.007111,"end_time":"2023-01-02T13:32:00.124262","exception":false,"start_time":"2023-01-02T13:32:00.117151","status":"completed"},"tags":[],"id":"e0fa1463"},"source":["# Case 0. Learning basics\n","**Neural Networks for Machine Learning Applications**<br>\n","24.01.2024<br>\n","Rabindra Manandhar<br>\n","[Information Technology, Bachelor's Degree](https://www.metropolia.fi/en/academics/bachelors-degrees/information-technology)<br>\n","[Metropolia University of Applied Sciences](https://www.metropolia.fi/en)\n","\n","- **v3**: Simplified version based on discussion with JK.\n","- **v4**: Added conversion of labels [to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) and changed the loss function to [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_crossentropy).\n","- **v5**: Changes in instructions wordings."]},{"cell_type":"markdown","id":"13803b03","metadata":{"papermill":{"duration":0.006806,"end_time":"2023-01-02T13:32:00.137773","exception":false,"start_time":"2023-01-02T13:32:00.130967","status":"completed"},"tags":[],"id":"13803b03"},"source":["## 1. Introduction\n","\n","\n","This notebook was created to learn to use basic Tensorflow neural network functions.\n","\n","The main objectives were to find a simple neural network model and train it to classify the black and white handwritten digits in a small number of epochs."]},{"cell_type":"markdown","id":"edec8fdd","metadata":{"papermill":{"duration":0.005269,"end_time":"2023-01-02T13:32:00.149245","exception":false,"start_time":"2023-01-02T13:32:00.143976","status":"completed"},"tags":[],"id":"edec8fdd"},"source":["## 2. Setup\n","\n","'Tensorflow' library was used here. It was used to build and train a neural network model."]},{"cell_type":"code","execution_count":null,"id":"faa11d6a","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:00.163235Z","iopub.status.busy":"2023-01-02T13:32:00.162563Z","iopub.status.idle":"2023-01-02T13:32:07.133827Z","shell.execute_reply":"2023-01-02T13:32:07.131277Z"},"papermill":{"duration":6.983144,"end_time":"2023-01-02T13:32:07.138097","exception":false,"start_time":"2023-01-02T13:32:00.154953","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"faa11d6a","executionInfo":{"status":"ok","timestamp":1706258886091,"user_tz":-120,"elapsed":3865,"user":{"displayName":"Rabindra Manandhar","userId":"03577533680466798761"}},"outputId":"99fa7ac2-fe55-4439-ae78-b99fb9ccfb15"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow: 2.15.0\n"]}],"source":["import tensorflow as tf\n","print(f'tensorflow: {tf.__version__}')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"WPI5ZWWjiPfz","executionInfo":{"status":"ok","timestamp":1706268649545,"user_tz":-120,"elapsed":25011,"user":{"displayName":"Rabindra Manandhar","userId":"03577533680466798761"}},"outputId":"c0531609-c235-476f-9d89-6160bfd983b6","colab":{"base_uri":"https://localhost:8080/"}},"id":"WPI5ZWWjiPfz","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"befee899","metadata":{"papermill":{"duration":0.005507,"end_time":"2023-01-02T13:32:07.149787","exception":false,"start_time":"2023-01-02T13:32:07.144280","status":"completed"},"tags":[],"id":"befee899"},"source":["## 3. Dataset\n","\n","The MNIST dataset comes preloaded in Keras, in the form of a set of four Numpy arrays/tensors. x_train and y_train form the training set, the data that the model will learn from. The model will then be tested on the test set, x_test and y_test. The images are encoded as NumPy arrays, and the labels are an array of digits, ranging from 0 to 9. The images and labels have a one-to-one correspondence.*italicized text*"]},{"cell_type":"code","execution_count":null,"id":"3328572b","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:07.175856Z","iopub.status.busy":"2023-01-02T13:32:07.174917Z","iopub.status.idle":"2023-01-02T13:32:09.048194Z","shell.execute_reply":"2023-01-02T13:32:09.046787Z"},"papermill":{"duration":1.88471,"end_time":"2023-01-02T13:32:09.052001","exception":false,"start_time":"2023-01-02T13:32:07.167291","status":"completed"},"tags":[],"id":"3328572b"},"outputs":[],"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":null,"id":"ab0faf75","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:09.069295Z","iopub.status.busy":"2023-01-02T13:32:09.068750Z","iopub.status.idle":"2023-01-02T13:32:09.077632Z","shell.execute_reply":"2023-01-02T13:32:09.075794Z"},"papermill":{"duration":0.022781,"end_time":"2023-01-02T13:32:09.080918","exception":false,"start_time":"2023-01-02T13:32:09.058137","status":"completed"},"tags":[],"id":"ab0faf75","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706258886091,"user_tz":-120,"elapsed":3,"user":{"displayName":"Rabindra Manandhar","userId":"03577533680466798761"}},"outputId":"fa768056-4c0a-4e06-c58f-94c10530e97b"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train: shape (60000, 28, 28) and ndim 3\n","x_test:  shape (10000, 28, 28) and ndim 3\n","y_train: shape (60000,) and ndim 1\n","y_test:  shape (10000,) and ndim 1\n"]}],"source":["print(f'x_train: shape {x_train.shape} and ndim {x_train.ndim}')\n","print(f'x_test:  shape {x_test.shape} and ndim {x_test.ndim}')\n","\n","print(f'y_train: shape {y_train.shape} and ndim {y_train.ndim}')\n","print(f'y_test:  shape {y_test.shape} and ndim {y_test.ndim}')"]},{"cell_type":"markdown","id":"bd14c510","metadata":{"papermill":{"duration":0.005694,"end_time":"2023-01-02T13:32:09.092742","exception":false,"start_time":"2023-01-02T13:32:09.087048","status":"completed"},"tags":[],"id":"bd14c510"},"source":["## 4. Preprocessing\n","\n","1. Normalization of Input Data:\n","Since the pixel values in images, x_train and x_test in this case, typically range from 0 to 255, dividing by 255.0 scales the pixel values to be in the range [0,1] in data type - float64. Normalizing the data helps in speeding up the training process and improving the convergence of the optimization algorithm.\n","\n","2. Categorical/Binary representation of Labels:\n","The labels, y_train and y_test in this case, are each converted into a binary vector of length equal to the number of classes. The element corresponding to the class label is set to 1, and all other elements are set to 0.\n","\n","    By normalizing the input data and converting the labels to categorical representation, we prepare the dataset for training a neural network model, which can efficiently learn from the data and make predictions on unseen samples. These preprocessing steps are common in many machine learning and deep learning tasks, especially for image classification problems like the MNIST digit recognition task."]},{"cell_type":"code","execution_count":null,"id":"6a47b3d2","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:09.119338Z","iopub.status.busy":"2023-01-02T13:32:09.118817Z","iopub.status.idle":"2023-01-02T13:32:09.414100Z","shell.execute_reply":"2023-01-02T13:32:09.412412Z"},"papermill":{"duration":0.306799,"end_time":"2023-01-02T13:32:09.417891","exception":false,"start_time":"2023-01-02T13:32:09.111092","status":"completed"},"tags":[],"id":"6a47b3d2"},"outputs":[],"source":["x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","y_train = tf.keras.utils.to_categorical(y_train)\n","y_test = tf.keras.utils.to_categorical(y_test)"]},{"cell_type":"markdown","id":"c662a878","metadata":{"papermill":{"duration":0.005791,"end_time":"2023-01-02T13:32:09.430010","exception":false,"start_time":"2023-01-02T13:32:09.424219","status":"completed"},"tags":[],"id":"c662a878"},"source":["## 5. Modeling\n","\n","The core building block of neural networks is the layer. The layer is like a filter for data: some data goes in, and it comes out in a more useful form.\n","\n","Here, our model is a simple feedforward neural network with linear stack of layers, one input layer (Flatten), one hidden layer (Dense with ReLU activation) and one output layer (Dense with softmax activation). The network is designed to take 28x28 pixel images as input and output the probabilities of each digit class(0 through 9).\n","\n","Flatten layer is the input layer of the neural network, transform 2D input data (28x28) into a 1D array(28x28=784 elements) and flattens the input while preserving the batch size.\n","\n","First Dense layer is a fully connected hidden layer with 200 neurons in this case and ReLU activation function. Each neuron in this layer is connected to every neuron in the previous layer. This layer introduces non-linearity to the model and helps in learning complex patterns in the data.\n","\n","Second Dense layer is the output layer layer of the neural network. It has 10 neurons, each representing one of the possible digit classes (0 through 9). The 'softmax' activation function is used in the output layer for multi-class classification tasks. It converts the raw output values into probabilities, where each value represents the probability of the corresponding class."]},{"cell_type":"code","execution_count":null,"id":"9bb76cba","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:09.459496Z","iopub.status.busy":"2023-01-02T13:32:09.458919Z","iopub.status.idle":"2023-01-02T13:32:09.623647Z","shell.execute_reply":"2023-01-02T13:32:09.622312Z"},"papermill":{"duration":0.176374,"end_time":"2023-01-02T13:32:09.627240","exception":false,"start_time":"2023-01-02T13:32:09.450866","status":"completed"},"tags":[],"id":"9bb76cba"},"outputs":[],"source":["model = tf.keras.models.Sequential([ # is a linear stack of layers, allows to build a model by adding layers one by one is sequence.\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(200, activation='relu'),\n","  tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","#model.summary()"]},{"cell_type":"code","source":["#from tensorflow.keras.utils import plot_model\n","\n","#plot_model(model, show_shapes = True, show_layer_activations = True)"],"metadata":{"id":"DfAmFl3yoilS"},"id":"DfAmFl3yoilS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To make the model ready for training, we need to pick three more things as part of the compilation step:\n","\n","An optimizer — The mechanism through which the model will update the weights of the neural network based on the training data it sees during training , so as to improve its performance i.e. to minimize the loss function.\n","\n","A loss function — How the model will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n","\n","Metrics - to monitor and evaluate the performance of the model during training and testing — Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."],"metadata":{"id":"wMY5uEvaYybe"},"id":"wMY5uEvaYybe"},{"cell_type":"code","execution_count":null,"id":"14b85188","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:09.643049Z","iopub.status.busy":"2023-01-02T13:32:09.642490Z","iopub.status.idle":"2023-01-02T13:32:09.937352Z","shell.execute_reply":"2023-01-02T13:32:09.935832Z"},"papermill":{"duration":0.307327,"end_time":"2023-01-02T13:32:09.941020","exception":false,"start_time":"2023-01-02T13:32:09.633693","status":"completed"},"tags":[],"id":"14b85188"},"outputs":[],"source":["model.compile(optimizer = 'adam',\n","              loss = 'categorical_crossentropy',\n","              metrics = ['accuracy'])"]},{"cell_type":"markdown","id":"213769f8","metadata":{"papermill":{"duration":0.006495,"end_time":"2023-01-02T13:32:09.953690","exception":false,"start_time":"2023-01-02T13:32:09.947195","status":"completed"},"tags":[],"id":"213769f8"},"source":["## 6. Training\n","\n","In keras, fit() method is used to train the neural network model on a given dataset.\n","\n","During training, the model will perform the following steps for each epoch:\n","\n","Forward pass: The model takes the input data (x_train) and passes it through the neural network to generate predictions.\n","\n","Computation of loss: The model computes the loss, which is a measure of how well the predictions match the true labels (y_train).\n","\n","Backward pass (Backpropagation): The model calculates the gradients of the loss with respect to the model's parameters (weights and biases) using backpropagation.\n","\n","Optimization: The optimizer adjusts the model's parameters based on the computed gradients to minimize the loss function.\n","\n","We require test set accuracy of 0.970. Hence, we first begin training with 1 epoch to see how much test accuracy is. In our case, the training with epoch = 1 gives an accuracy of 0.9307. Since, it did not achieve the desired test accuracy, we repeat the training with epoch = 2, which gives an accuracy of 0.9700. It is important to notice the number of neurons in the hidden layer is set to 200."]},{"cell_type":"code","execution_count":null,"id":"20fc668a","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:09.980253Z","iopub.status.busy":"2023-01-02T13:32:09.979742Z","iopub.status.idle":"2023-01-02T13:32:52.155779Z","shell.execute_reply":"2023-01-02T13:32:52.154375Z"},"papermill":{"duration":42.187775,"end_time":"2023-01-02T13:32:52.159410","exception":false,"start_time":"2023-01-02T13:32:09.971635","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"20fc668a","executionInfo":{"status":"ok","timestamp":1706258897865,"user_tz":-120,"elapsed":11401,"user":{"displayName":"Rabindra Manandhar","userId":"03577533680466798761"}},"outputId":"ec5190d5-f50a-424a-93de-c9feecf487bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2346 - accuracy: 0.9317\n","Epoch 2/2\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.0969 - accuracy: 0.9711\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x79533aa1fd00>"]},"metadata":{},"execution_count":8}],"source":["model.fit(x_train, y_train, epochs = 2)"]},{"cell_type":"markdown","source":["The training process continued for the specified number of epochs (2 in this case) with 200 neurons in the hidden layer, and after training completed, the model will have learned to make predictions based on the input data. The accuracy of the model on the training data will depend on various factors, including the model architecture, optimizer, and the complexity of the dataset."],"metadata":{"id":"uy4oqcHvxdFp"},"id":"uy4oqcHvxdFp"},{"cell_type":"markdown","id":"7f63ccbc","metadata":{"papermill":{"duration":0.043466,"end_time":"2023-01-02T13:32:52.247833","exception":false,"start_time":"2023-01-02T13:32:52.204367","status":"completed"},"tags":[],"id":"7f63ccbc"},"source":["## 7. Performance and evaluation\n","\n","Now that we have trained our model, we check that on average, how good is our model at classifying never-before-seen digits by computing average accuracy over the entire test set using evaluate() method in Keras.\n"]},{"cell_type":"code","execution_count":null,"id":"6acb0119","metadata":{"execution":{"iopub.execute_input":"2023-01-02T13:32:52.429911Z","iopub.status.busy":"2023-01-02T13:32:52.429420Z","iopub.status.idle":"2023-01-02T13:32:53.215567Z","shell.execute_reply":"2023-01-02T13:32:53.214103Z"},"papermill":{"duration":0.835956,"end_time":"2023-01-02T13:32:53.218556","exception":false,"start_time":"2023-01-02T13:32:52.382600","status":"completed"},"tags":[],"id":"6acb0119","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706258898227,"user_tz":-120,"elapsed":384,"user":{"displayName":"Rabindra Manandhar","userId":"03577533680466798761"}},"outputId":"9d0cddf8-c15f-484a-c380-3f912d963a78"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 0s - loss: 0.0832 - accuracy: 0.9748 - 438ms/epoch - 1ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.0831959992647171, 0.9747999906539917]"]},"metadata":{},"execution_count":9}],"source":["model.evaluate(x_test,  y_test, verbose=2) # The parameter verbose controls the verbosity mode during evaluation. verbose=2 displays one line of output per epoch\n"]},{"cell_type":"markdown","id":"74a87730","metadata":{"papermill":{"duration":0.047202,"end_time":"2023-01-02T13:32:53.309310","exception":false,"start_time":"2023-01-02T13:32:53.262108","status":"completed"},"tags":[],"id":"74a87730"},"source":["## 8. Discussion and conclusions"]},{"cell_type":"markdown","id":"3f291d77","metadata":{"papermill":{"duration":0.046072,"end_time":"2023-01-02T13:32:53.404349","exception":false,"start_time":"2023-01-02T13:32:53.358277","status":"completed"},"tags":[],"id":"3f291d77"},"source":["- Which settings were tested before the best model was found\n","\n","  I tested number of neurons in hidden layer, number of epochs as well as added batch_size.\n","\n","- Summary of what was your best model and its settings\n","\n","  Firstly, I tested with 10 neurons in hidden layer and epochs=1. I gruadually increased the number of neurons in the hidden layer to 128 and epochs=2. I subsequently increased the number of neurons to 256 keeping epochs same, achieving test set accuracy of over 0.970. Hence, I reduced the number of neurons to 200, and finally achieved the test set accuracy of 0.970.\n","\n","- What was the final achieved performance\n","\n","  loss: 0.0966, accuracy: 0.9686\n","\n","- What are your main observations and learning points\n","\n","  a. Preprocessing techniques such as normalization are essential when working with image data.\n","\n","  b. Experimenting and exploring activation functions, losss functions and optimizers.\n","\n","  c. The number of neurons in a hidden layer directly affects the capacity of the model to learn complex patterns in the data.\n","\n","  d. Understanding evaluation metrics such as accuracy.\n","\n","- Discussion how the model could be improved in future.\n","\n","  We are in the first steps of understanding deep learning. Hence, I have no points to discuss how this model could be improved."]},{"cell_type":"markdown","id":"7ae26fff","metadata":{"papermill":{"duration":0.045656,"end_time":"2023-01-02T13:32:53.498148","exception":false,"start_time":"2023-01-02T13:32:53.452492","status":"completed"},"tags":[],"id":"7ae26fff"},"source":["To learn more, see [Tensorflow tutorials](https://www.tensorflow.org/tutorials)."]},{"cell_type":"code","source":[],"metadata":{"id":"oEcGU6_pILw5"},"id":"oEcGU6_pILw5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":68.433454,"end_time":"2023-01-02T13:32:56.774790","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-02T13:31:48.341336","version":"2.3.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}